{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>change_after_3_days</th>\n",
       "      <th>change_after_2_days</th>\n",
       "      <th>change_after_1_days</th>\n",
       "      <th>binary_sentiment_after_3_days</th>\n",
       "      <th>sentiment_after_3_days</th>\n",
       "      <th>binary_sentiment_after_2_days</th>\n",
       "      <th>sentiment_after_2_days</th>\n",
       "      <th>binary_sentiment_after_1_days</th>\n",
       "      <th>sentiment_after_1_days</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2008-03-31</th>\n",
       "      <td>12262.889648</td>\n",
       "      <td>273610000</td>\n",
       "      <td>1.839884</td>\n",
       "      <td>0.450750</td>\n",
       "      <td>-0.895215</td>\n",
       "      <td>pos</td>\n",
       "      <td>negative</td>\n",
       "      <td>pos</td>\n",
       "      <td>negative</td>\n",
       "      <td>neg</td>\n",
       "      <td>positive</td>\n",
       "      <td>resource warssilver gold the last american her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-01</th>\n",
       "      <td>12654.360352</td>\n",
       "      <td>295530000</td>\n",
       "      <td>-5.659022</td>\n",
       "      <td>-10.133497</td>\n",
       "      <td>-2.294553</td>\n",
       "      <td>neg</td>\n",
       "      <td>positive</td>\n",
       "      <td>neg</td>\n",
       "      <td>positive</td>\n",
       "      <td>neg</td>\n",
       "      <td>positive</td>\n",
       "      <td>usa the great depressionventure capitalist fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-02</th>\n",
       "      <td>12608.919922</td>\n",
       "      <td>232760000</td>\n",
       "      <td>-3.177763</td>\n",
       "      <td>-4.816371</td>\n",
       "      <td>0.971870</td>\n",
       "      <td>neg</td>\n",
       "      <td>positive</td>\n",
       "      <td>neg</td>\n",
       "      <td>positive</td>\n",
       "      <td>pos</td>\n",
       "      <td>negative</td>\n",
       "      <td>bush caused the financial market meltdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-04</th>\n",
       "      <td>12609.419922</td>\n",
       "      <td>181260000</td>\n",
       "      <td>2.246841</td>\n",
       "      <td>-0.011266</td>\n",
       "      <td>0.018968</td>\n",
       "      <td>pos</td>\n",
       "      <td>negative</td>\n",
       "      <td>neg</td>\n",
       "      <td>neutral</td>\n",
       "      <td>pos</td>\n",
       "      <td>neutral</td>\n",
       "      <td>the death of financial systemfed interest rate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008-04-11</th>\n",
       "      <td>12325.419922</td>\n",
       "      <td>286850000</td>\n",
       "      <td>6.365066</td>\n",
       "      <td>5.246454</td>\n",
       "      <td>4.319129</td>\n",
       "      <td>pos</td>\n",
       "      <td>negative</td>\n",
       "      <td>pos</td>\n",
       "      <td>negative</td>\n",
       "      <td>pos</td>\n",
       "      <td>negative</td>\n",
       "      <td>the black death of financial collapserich coun...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Close     Volume  change_after_3_days  change_after_2_days  \\\n",
       "2008-03-31  12262.889648  273610000             1.839884             0.450750   \n",
       "2008-04-01  12654.360352  295530000            -5.659022           -10.133497   \n",
       "2008-04-02  12608.919922  232760000            -3.177763            -4.816371   \n",
       "2008-04-04  12609.419922  181260000             2.246841            -0.011266   \n",
       "2008-04-11  12325.419922  286850000             6.365066             5.246454   \n",
       "\n",
       "            change_after_1_days binary_sentiment_after_3_days  \\\n",
       "2008-03-31            -0.895215                           pos   \n",
       "2008-04-01            -2.294553                           neg   \n",
       "2008-04-02             0.971870                           neg   \n",
       "2008-04-04             0.018968                           pos   \n",
       "2008-04-11             4.319129                           pos   \n",
       "\n",
       "           sentiment_after_3_days binary_sentiment_after_2_days  \\\n",
       "2008-03-31               negative                           pos   \n",
       "2008-04-01               positive                           neg   \n",
       "2008-04-02               positive                           neg   \n",
       "2008-04-04               negative                           neg   \n",
       "2008-04-11               negative                           pos   \n",
       "\n",
       "           sentiment_after_2_days binary_sentiment_after_1_days  \\\n",
       "2008-03-31               negative                           neg   \n",
       "2008-04-01               positive                           neg   \n",
       "2008-04-02               positive                           pos   \n",
       "2008-04-04                neutral                           pos   \n",
       "2008-04-11               negative                           pos   \n",
       "\n",
       "           sentiment_after_1_days  \\\n",
       "2008-03-31               positive   \n",
       "2008-04-01               positive   \n",
       "2008-04-02               negative   \n",
       "2008-04-04                neutral   \n",
       "2008-04-11               negative   \n",
       "\n",
       "                                                  title_clean  \n",
       "2008-03-31  resource warssilver gold the last american her...  \n",
       "2008-04-01  usa the great depressionventure capitalist fre...  \n",
       "2008-04-02          bush caused the financial market meltdown  \n",
       "2008-04-04  the death of financial systemfed interest rate...  \n",
       "2008-04-11  the black death of financial collapserich coun...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import google.datalab.storage as storage\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "\n",
    "mybucket = storage.Bucket('bharti_patel')\n",
    "data_csv = mybucket.object('merged_data.csv')\n",
    "\n",
    "uri = data_csv.uri\n",
    "%gcs read --object $uri --variable data\n",
    "df = pd.read_csv(BytesIO(data), index_col=0, parse_dates=True, infer_datetime_format=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = df.title_clean\n",
    "y = df.sentiment_after_3_days\n",
    "z = df.binary_sentiment_after_3_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/envs/py3env/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(x)\n",
    "sequences = tokenizer.texts_to_sequences(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "max_sentlen = max([len(x) for x in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (1310, 754)\n"
     ]
    }
   ],
   "source": [
    "x_seq = pad_sequences(sequences, maxlen=max_sentlen)\n",
    "#x_r, x_c = x_seq.shape\n",
    "#x_seq = x_seq.reshape(1,x_r,x_c)\n",
    "\n",
    "print('Shape of data tensor:', x_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of seq_label tensor: (1310,)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "enc = LabelEncoder()\n",
    "onehot = OneHotEncoder(sparse=False)\n",
    "seq_label = enc.fit_transform(y)\n",
    "#seq_label = seq_label.reshape(len(seq_label), 1)\n",
    "#seq_label_hot = onehot.fit_transform(seq_label)\n",
    "print('Shape of seq_label tensor:', seq_label.shape)\n",
    "print(seq_label[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "# load the whole embedding into memory\n",
    "embeddings_index = dict()\n",
    "f = open('./glove.6B.100d.txt', encoding='utf-8')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "# find the embedding vector dimensions size from the most common word in english: 'the'\n",
    "# http://www.dictionary.com/e/commonwords/\n",
    "embedding_size = len(embeddings_index['the'])\n",
    "print (embedding_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n",
      "61211\n",
      "Shape of embedding matrix: (61211, 100)\n"
     ]
    }
   ],
   "source": [
    "print('Loaded %s word vectors.' % len(embeddings_index))\n",
    "# create a weight matrix for words in training docs\n",
    "print(vocab_size)\n",
    "embedding_matrix = zeros((vocab_size, embedding_size))\n",
    "print('Shape of embedding matrix:', embedding_matrix.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training sequences shape: (1048, 754)\n",
      "Training labels shape: (1048, 3)\n",
      "Test sequences shape: (131, 754)\n",
      "Test labels shape: (131, 3)\n",
      "Validation sequences shape: (130, 754)\n",
      "Validation labels shape: (130, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "n_samples = len(x_seq)\n",
    "train_pct = 0.8\n",
    "test_pct = 1 - train_pct\n",
    "SEED = 2000\n",
    "seq_label = to_categorical(seq_label)\n",
    "x_seq_train, x_seq_validation_test, seq_label_train,seq_label_validation_test = train_test_split(x_seq, seq_label, test_size=int(test_pct*n_samples), train_size=int(train_pct*n_samples), random_state=SEED)\n",
    "x_seq_validation,x_seq_test,seq_label_validation,seq_label_test = train_test_split(x_seq_validation_test,seq_label_validation_test,test_size=.5, random_state=SEED)\n",
    "\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "#SEED = 2000\n",
    "#x_train, x_validation_and_test, y_train, y_validation_and_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "#x_validation, x_test, y_validation, y_test = train_test_split(x_validation_and_test, y_validation_and_test, test_size=.5, random_state=SEED)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.02, random_state=SEED)\n",
    "\n",
    "print(\"Training sequences shape:\", x_seq_train.shape)\n",
    "print(\"Training labels shape:\",seq_label_train.shape)\n",
    "print(\"Test sequences shape:\", x_seq_test.shape)\n",
    "print(\"Test labels shape:\", seq_label_test.shape)\n",
    "print(\"Validation sequences shape:\", x_seq_validation.shape)\n",
    "print(\"Validation labels shape:\", seq_label_validation.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import Flatten\n",
    "import tensorflow as tf\n",
    "import keras_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def as_keras_metric(method):\n",
    "    import functools\n",
    "    from keras import backend as K\n",
    "    import tensorflow as tf\n",
    "    @functools.wraps(method)\n",
    "    def wrapper(self, args, **kwargs):\n",
    "        \"\"\" Wrapper for turning tensorflow metrics into keras metrics \"\"\"\n",
    "        value, update_op = method(self, args, **kwargs)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([update_op]):\n",
    "            value = tf.identity(value)\n",
    "        return value\n",
    "    return wrapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "precision = as_keras_metric(tf.metrics.precision)\n",
    "recall = as_keras_metric(tf.metrics.recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 754, 100)          6121100   \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 200)               160800    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 201       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 6         \n",
      "=================================================================\n",
      "Total params: 6,282,107\n",
      "Trainable params: 6,282,107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = Sequential()\n",
    "e = Embedding(vocab_size, embedding_size, weights=[embedding_matrix], input_length=max_sentlen, mask_zero=True)\n",
    "#e = Embedding(vocab_size, embedding_size, weights=[embedding_matrix], input_length=max_sentlen)\n",
    "model.add(e)\n",
    "model.add(Bidirectional(LSTM(embedding_size, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(Dense(1))\n",
    "model.add(Dense(3, activation='sigmoid'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy',keras_metrics.precision(), keras_metrics.recall()])\n",
    "# summarize the model\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# fit the model\n",
    "model.fit(x_seq_train, seq_label_train, epochs=50, verbose=0,validation_data=(x_seq_validation, seq_label_validation))\n",
    "# evaluate the model\n",
    "loss, accuracy, precision, recall = model.evaluate(x_seq_test, seq_label_test, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.549618, precision: 0.448322, recall: 0.893130, f1_score: 0.596980\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: %f, precision: %f, recall: %f, f1_score: %f' % ((accuracy), (precision), (recall), (2 * precision * recall / (precision + recall))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
